# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: Push Binary Nightly

on:
  # For debugging, enable push/pull_request
  pull_request:
    branches:
      - main
  # run every day at 10:45 AM
  # schedule:
  #   - cron:  '45 10 * * *'
  # or manually trigger it
  # workflow_dispatch:

jobs:
  # build on cpu hosts and upload to GHA
  build_on_cpu:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        include:
         - os: ubuntu-latest
           python-version: 3.7
           python-tag: "py37"
           cuda-tag: "cu11"
         - os: ubuntu-latest
           python-version: 3.8
           python-tag: "py38"
           cuda-tag: "cu11"
         - os: ubuntu-latest
           python-version: 3.9
           python-tag: "py39"
           cuda-tag: "cu11"
    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Check ldd --version
      run: ldd --version
    - name: Checkout
      uses: actions/checkout@v2
      with:
        submodules: true
    # Update references
    - name: Git Sumbodule Update
      run: |
        cd fbgemm_gpu/
        git submodule sync
        git submodule update --init --recursive
    - name: Setup conda
      run: |
        wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
        bash ~/miniconda.sh -b -p $HOME/miniconda -u
    - name: Setup PATH with conda
      run: |
        echo "/home/ec2-user/miniconda/bin" >> $GITHUB_PATH
        echo "CONDA=/home/ec2-user/miniconda" >> $GITHUB_PATH
    - name: Create conda env
      run: |
        conda create --name build_binary python=${{ matrix.python-version }}
        conda info
    - name: check python version
      run: |
        conda run -n build_binary python --version
    - name: Install PyTorch and CUDA
      shell: bash
      run: |
        conda install -y pytorch pytorch-cuda=11.7 -c pytorch-nightly -c nvidia
        conda install -y cudnn numpy scikit-build jinja2 ninja cmake hypothesis
    - name: nvcc check
      run: |
        nvcc --version
    - name: Install Dependencies
      shell: bash
      run: |
        cd fbgemm_gpu/
        conda run -n build_binary python -m pip install -r requirements.txt
    - name: Test Installation of dependencies
      run: |
        cd fbgemm_gpu/
        conda run -n build_binary python -c "import torch.distributed"
        echo "torch.distributed succeeded"
        conda run -n build_binary python -c "import skbuild"
        echo "skbuild succeeded"
        conda run -n build_binary python -c "import numpy"
        echo "numpy succeeded"
    # for the conda run with quotes, we have to use "\" and double quotes
    # here is the issue: https://github.com/conda/conda/issues/10972
    - name: Build FBGEMM_GPU Nightly
      run: |
        cd fbgemm_gpu/
        rm -r dist || true
        # buld cuda7.0;8.0 for v100/a100 arch:
        # Couldn't build more cuda arch due to 100 MB binary size limit from
        # pypi website.
        # manylinux1_x86_64 is specified for pypi upload:
        # distribute python extensions as wheels on Linux
        conda run -n build_binary \
          python setup.py bdist_wheel \
          --package_name=fbgemm_gpu_nightly \
          --python-tag=${{ matrix.python-tag }} \
          -DTORCH_CUDA_ARCH_LIST="'7.0;8.0'" \
          --plat-name=manylinux1_x86_64
        ls -lt dist/*.whl
